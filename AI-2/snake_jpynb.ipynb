{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snake.jpynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvpHyza8OrQC"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import sys\n",
        "import io\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from random import randint\n",
        "import os\n",
        "import itertools\n",
        "\n",
        "import random\n",
        "import pickle\n",
        "from io import BytesIO\n",
        "import json\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3JxkSpSDCbh"
      },
      "source": [
        "# helper function for movement\n",
        "import numpy as np\n",
        "from random import randint\n",
        "\n",
        "def vector_add(a, b):\n",
        "  x = a[0] + b[0]\n",
        "  y = a[1] + b[1]\n",
        "  return (x,y)\n",
        "\n",
        "generation_score = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbUHveQH94md"
      },
      "source": [
        "import time\n",
        "\n",
        "class Game:\n",
        "  def __init__(self):\n",
        "    self.grid = np.zeros((20,20))\n",
        "    self.pos = [(10,10)]\n",
        "    self.speed = 1\n",
        "    self.direction = 0\n",
        "    self.length = 1\n",
        "    self.apple_pos = (5,5)\n",
        "    self.playing = True\n",
        "    self.since_ate = 0\n",
        "\n",
        "  def update(self):\n",
        "    self.since_ate += 1\n",
        "    for i in range(self.length-1,0,-1):\n",
        "        self.pos[i] = self.pos[i-1]\n",
        "\n",
        "    if self.direction == 0:\n",
        "        self.pos[0] = vector_add(self.pos[0], (1, 0))\n",
        "    if self.direction == 1:\n",
        "        self.pos[0] = vector_add(self.pos[0], (-1, 0))\n",
        "    if self.direction == 2:\n",
        "        self.pos[0] = vector_add(self.pos[0], (0, 1))\n",
        "    if self.direction == 3:\n",
        "        self.pos[0] = vector_add(self.pos[0], (0, -1))\n",
        "    \n",
        "    # check to see for collision with self\n",
        "\n",
        "    self.playing = not self.get_crashed()\n",
        "\n",
        "    if self.ateApple(self.apple_pos[0], self.apple_pos[1]):\n",
        "      # print('ate apple')\n",
        "      self.length += 1\n",
        "      self.pos.append((0,0))\n",
        "      self.apple_pos = self.generate_apple_pos()\n",
        "      self.since_ate = 0\n",
        "\n",
        "    # time.sleep(.00001)\n",
        "\n",
        "  def moveRight(self):\n",
        "    if vector_add(self.pos[0], (1, 0)) not in self.pos:\n",
        "      self.direction = 0\n",
        "\n",
        "  def moveLeft(self):\n",
        "    if vector_add(self.pos[0], (-1, 0)) not in self.pos:\n",
        "      self.direction = 1\n",
        "\n",
        "  def moveUp(self):\n",
        "    if vector_add(self.pos[0], (0, 1)) not in self.pos:\n",
        "      self.direction = 2\n",
        "\n",
        "  def moveDown(self):\n",
        "    if vector_add(self.pos[0], (0, -1)) not in self.pos:\n",
        "      self.direction = 3\n",
        "\n",
        "  def get_crashed(self):\n",
        "    x, y = self.pos[0]\n",
        "    outside = (x < 0 or x >= 20 or y < 0 or y >= 20)\n",
        "    inside = self.isCollision(self.pos[0][0], self.pos[0][1])\n",
        "    length = self.length > 361\n",
        "    return outside or inside or length\n",
        "  \n",
        "  def get_playing(self):\n",
        "    return not self.get_crashed(self)\n",
        "\n",
        "  def isCollision(self,x1,y1):\n",
        "    return (x1, y1) in self.pos[1:]\n",
        "  \n",
        "  def ateApple(self, x1, y1):\n",
        "    return (x1, y1) in self.pos\n",
        "\n",
        "  def get_apple_pos(self):\n",
        "    return self.apple_pos\n",
        "\n",
        "  def generate_apple_pos(self):\n",
        "    generate = True\n",
        "    while(generate):\n",
        "      x = randint(1,19)\n",
        "      y = randint(1,19)\n",
        "\n",
        "      if (x, y) not in self.pos:\n",
        "        return (x, y)\n",
        "\n",
        "  def get_length(self):\n",
        "    return self.length\n",
        "\n",
        "  def do_nothing(self):\n",
        "    self.direction = self.direction\n",
        "  \n",
        "  def restart(self):\n",
        "    # print(\"restarting\")\n",
        "    self.pos = [(10,10)]\n",
        "    self.speed = 1\n",
        "    self.direction = 0\n",
        "    self.length = 1\n",
        "    self.apple_pos = (5,5)\n",
        "    self.playing = True\n",
        "    self.since_ate = 0\n",
        "\n",
        "  def get_grid(self):\n",
        "    grid = np.zeros((20, 20))\n",
        "    for i in range(len(self.pos)):\n",
        "      x, y = self.pos[i]\n",
        "      grid[x, y] = 1\n",
        "    x, y = self.apple_pos\n",
        "    grid[x,y] = 100\n",
        "    return grid\n",
        "\n",
        "  def time_since_ate(self):\n",
        "    return self.since_ate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETpnxTz_GDYJ"
      },
      "source": [
        "game = Game()\n",
        "# print(game.apple_pos)\n",
        "# print(game.pos)\n",
        "# for i in range(20):\n",
        "#   game.moveDown()\n",
        "#   game.update()\n",
        "#   game.moveLeft()\n",
        "#   game.update()\n",
        "# print(game.pos)\n",
        "# print(game.get_crashed())\n",
        "# print(game.playing)\n",
        "# print(game.length)\n",
        "# print(game.apple_pos)\n",
        "\n",
        "# cont = True\n",
        "\n",
        "# while(cont):\n",
        "#   print(game.pos)\n",
        "#   print(game.apple_pos)\n",
        "#   print(game.since_ate)\n",
        "#   a = input(\"input move: \")\n",
        "#   if int(a) in [0,1,2,3,4]:\n",
        "#     a = int(a)\n",
        "#     print(a)\n",
        "#     if a == 0:\n",
        "#       game.moveLeft()\n",
        "#       game.update()\n",
        "#     elif a == 1:\n",
        "#       game.moveRight()\n",
        "#       game.update()\n",
        "#     elif a == 2:\n",
        "#       game.moveDown()\n",
        "#       game.update()\n",
        "#     elif a == 3:\n",
        "#       game.moveUp()\n",
        "#       game.update()\n",
        "#     elif a == 4:\n",
        "#       game.update()\n",
        "#   if a == 'end':\n",
        "#     cont = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iddvkIxJi9i"
      },
      "source": [
        "class SnakeAgent:\n",
        "  def __init__(self, game):\n",
        "    self.snakeGame = game\n",
        "  def is_running(self):\n",
        "    return self.snakeGame.get_playing()\n",
        "  def is_crashed(self):\n",
        "    return self.snakeGame.get_crashed()\n",
        "  def left(self):\n",
        "    self.snakeGame.moveLeft()\n",
        "  def right(self):\n",
        "    self.snakeGame.moveRight()\n",
        "  def down(self):\n",
        "    self.snakeGame.moveDown()\n",
        "  def up(self):\n",
        "    self.snakeGame.moveUp()\n",
        "  def DoNothing(self):\n",
        "    self.snakeGame.do_nothing()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60yiMk-WMlkA"
      },
      "source": [
        "class Game_State:\n",
        "  def __init__(self, agent, game):\n",
        "    self._agent = agent\n",
        "    self.snakeGame = game\n",
        "  def get_next_state(self, actions):\n",
        "    score = self.snakeGame.get_length()\n",
        "\n",
        "    reward = self.get_reward()\n",
        "    is_over = False\n",
        "\n",
        "    if actions[0] == 1:\n",
        "      self._agent.left()\n",
        "    elif actions[1] == 1:\n",
        "      self._agent.right()\n",
        "    elif actions[2] == 1:\n",
        "      self._agent.up()\n",
        "    elif actions[3] == 1:\n",
        "      self._agent.down()\n",
        "    elif actions[4] == 1:\n",
        "      self._agent.DoNothing()\n",
        "\n",
        "    self.snakeGame.update()\n",
        "\n",
        "    if self._agent.is_crashed():\n",
        "      generation_score.append(score)\n",
        "      # print(\"restart\")\n",
        "      time.sleep(.0001)\n",
        "      self.snakeGame.restart()\n",
        "      reward = -1\n",
        "      is_over = True\n",
        "\n",
        "    grid = self.snakeGame.get_grid()\n",
        "    grid = np.reshape(grid, (20,20,1))\n",
        "    grid = np.transpose(grid, (2,0,1))\n",
        "    tensor = torch.from_numpy(grid).type(torch.FloatTensor)\n",
        "    if torch.cuda.is_available():\n",
        "      tensor = tensor.cuda()\n",
        "\n",
        "    return tensor, reward, is_over, score\n",
        "  def get_reward(self):\n",
        "    # base = .00001+self.snakeGame.get_length()-1\n",
        "    length = self.snakeGame.get_length()\n",
        "    base = length*(length+1)/2 - 1\n",
        "    time = self.snakeGame.time_since_ate()\n",
        "    if time >= 10:\n",
        "      base -= time*.0001\n",
        "    \n",
        "    return base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbZn0i5PP4BZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "32ef6e63-d3cf-4991-b1b1-a7f30704709f"
      },
      "source": [
        "game = Game()\n",
        "agent = SnakeAgent(game)\n",
        "state = Game_State(agent, game)\n",
        "actions = [0,0,0,0,1]\n",
        "state.get_next_state(actions)\n",
        "state.get_next_state(actions)\n",
        "actions = [0,0,0,1,0]\n",
        "state.get_next_state(actions)\n",
        "\n",
        "for i in range(4):\n",
        "  state.get_next_state(actions)\n",
        "\n",
        "actions = [1,0,0,0,0]\n",
        "\n",
        "for i in range(6):\n",
        "  state.get_next_state(actions)\n",
        "\n",
        "state.get_next_state(actions)\n",
        "\n",
        "state.get_next_state(actions)\n",
        "a, b, c, d = state.get_next_state(actions)\n",
        "print(a.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 20, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZa9CUXyWeYu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "927586a3-d642-4eb8-c204-5174e8dfe4f2"
      },
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        self.number_of_actions = 5\n",
        "        self.gamma = 0.95\n",
        "        self.final_epsilon = 0.0001\n",
        "        self.initial_epsilon = 0.2\n",
        "        self.number_of_iterations = 500001\n",
        "        self.replay_memory_size = 10000\n",
        "        self.minibatch_size = 32\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(4, 32, 8, 2)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 4, 2)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        # self.fc4 = nn.Linear(256, 512)\n",
        "        # self.relu4 = nn.ReLU(inplace=True)\n",
        "        self.fc5 = nn.Linear(512 , self.number_of_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.relu2(out)\n",
        "        # out = self.conv3(out)\n",
        "        # out = self.relu3(out)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        # out = self.fc4(out)\n",
        "        # out = self.relu4(out)\n",
        "        out = self.fc5(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
        "        torch.nn.init.uniform(m.weight, -0.01, 0.01)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "def train(model, start):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    game = Game()\n",
        "    snake = SnakeAgent(game)\n",
        "    game_state = Game_State(snake,game)\n",
        "\n",
        "    replay_memory = []\n",
        "\n",
        "    action = torch.zeros([model.number_of_actions], dtype=torch.float32)\n",
        "    action[0] = 1\n",
        "    print(action)\n",
        "    image_data, reward, terminal, score = game_state.get_next_state(action)\n",
        "    print(image_data.shape)\n",
        "\n",
        "    state = torch.cat((image_data, image_data, image_data, image_data)).unsqueeze(0) #stacking 4 images\n",
        "\n",
        "    print(\"printing size of input state at 0\")\n",
        "    print(state.size())\n",
        "\n",
        "    epsilon = model.initial_epsilon\n",
        "    iteration = 0\n",
        "\n",
        "    epsilon_decrements = np.linspace(model.initial_epsilon, model.final_epsilon,model.number_of_iterations)\n",
        "\n",
        "    q_vals = []\n",
        "\n",
        "    while iteration < model.number_of_iterations:\n",
        "        output = model(state)[0]\n",
        "\n",
        "        action = torch.zeros([model.number_of_actions], dtype=torch.float32)\n",
        "        if torch.cuda.is_available():\n",
        "            action = action.cuda()\n",
        "\n",
        "        random_action = random.random() <= epsilon\n",
        "        action_index = [torch.randint(model.number_of_actions, torch.Size([]), dtype=torch.int)\n",
        "                        if random_action\n",
        "                        else torch.argmax(output)][0]\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            action_index = action_index.cuda()\n",
        "\n",
        "        action[action_index] = 1\n",
        "\n",
        "        image_data_1, reward, terminal, score = game_state.get_next_state(action)\n",
        "        state_1 = torch.cat((state.squeeze(0)[1:, :, :], image_data_1)).unsqueeze(0)\n",
        "\n",
        "        action = action.unsqueeze(0)\n",
        "        reward = torch.from_numpy(np.array([reward], dtype=np.float32)).unsqueeze(0)\n",
        "\n",
        "        replay_memory.append((state, action, reward, state_1, terminal))\n",
        "\n",
        "        if len(replay_memory) > model.replay_memory_size:\n",
        "            replay_memory.pop(0)\n",
        "\n",
        "        epsilon = epsilon_decrements[iteration]\n",
        "        minibatch = random.sample(replay_memory, min(len(replay_memory), model.minibatch_size))\n",
        "\n",
        "        state_batch = torch.cat(tuple(d[0] for d in minibatch))\n",
        "        action_batch = torch.cat(tuple(d[1] for d in minibatch))\n",
        "        reward_batch = torch.cat(tuple(d[2] for d in minibatch))\n",
        "        state_1_batch = torch.cat(tuple(d[3] for d in minibatch))\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            state_batch = state_batch.cuda()\n",
        "            action_batch = action_batch.cuda()\n",
        "            reward_batch = reward_batch.cuda()\n",
        "            state_1_batch = state_1_batch.cuda()\n",
        "\n",
        "        output_1_batch = model(state_1_batch)\n",
        "\n",
        "        y_batch = torch.cat(tuple(reward_batch[i] if minibatch[i][4]\n",
        "                                  else reward_batch[i] + model.gamma * torch.max(output_1_batch[i])\n",
        "                                  for i in range(len(minibatch))))\n",
        "\n",
        "        q_value = torch.sum(model(state_batch) * action_batch, dim=1)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_batch = y_batch.detach()\n",
        "        loss = criterion(q_value, y_batch)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        state = state_1\n",
        "\n",
        "        global generation_score\n",
        "        if len(generation_score) == 0:\n",
        "            avg_score = 0\n",
        "        else:\n",
        "            avg_score = sum(generation_score)/len(generation_score)\n",
        "\n",
        "        if iteration % 1000 == 0:\n",
        "            print(\"iteration:\", iteration, \"score:\", score, \"elapsed time:\", time.time() - start, \"epsilon:\", epsilon, \"action:\",\n",
        "                  action_index.cpu().detach().numpy(), \"reward:\", reward.numpy()[0][0], \"Q max:\",\n",
        "                  np.max(output.cpu().detach().numpy()), \"avg_score:\", avg_score)\n",
        "            q_vals.append(np.max(output.cpu().detach().numpy()))\n",
        "            generation_score = []\n",
        "\n",
        "        if iteration % 100000 == 0:\n",
        "            torch.save(model, \"pretrained-model/current_model_\" + str(iteration) + \".pth\")\n",
        "\n",
        "        iteration += 1\n",
        "    return q_vals\n",
        "\n",
        "def test(model):\n",
        "\n",
        "    game = Game()\n",
        "    snake = SnakeAgent(game)\n",
        "    game_state = Game_State(snake,game)\n",
        "\n",
        "\n",
        "    action = torch.zeros([model.number_of_actions], dtype=torch.float32)\n",
        "    action[0] = 1\n",
        "    image_data, reward, terminal, s_, = game_state.get_next_state(action)\n",
        "    state = torch.cat((image_data, image_data, image_data, image_data)).unsqueeze(0)\n",
        "\n",
        "    high_score = 0\n",
        "    tot_counter = 0\n",
        "    cur_counter = 0\n",
        "\n",
        "    while True:\n",
        "        output = model(state)[0]\n",
        "\n",
        "        action = torch.zeros([model.number_of_actions], dtype=torch.float32)\n",
        "        if torch.cuda.is_available():\n",
        "            action = action.cuda()\n",
        "\n",
        "        action_index = torch.argmax(output)\n",
        "        if torch.cuda.is_available():\n",
        "            action_index = action_index.cuda()\n",
        "        action[action_index] = 1\n",
        "\n",
        "        image_data_1, reward, terminal, s_ = game_state.get_next_state(action)\n",
        "        state_1 = torch.cat((state.squeeze(0)[1:, :, :], image_data_1)).unsqueeze(0)\n",
        "\n",
        "        # print(action)\n",
        "        if cur_counter >= 10000:\n",
        "          terminal = True\n",
        "\n",
        "        if terminal == True:\n",
        "          print(\"restarting\")\n",
        "          tot_counter += 1\n",
        "          if s_ > high_score:\n",
        "            high_score = s_\n",
        "            print(s_)\n",
        "          if tot_counter >= 200:\n",
        "            print(high_score)\n",
        "            return high_score\n",
        "        # time.sleep(.5)\n",
        "        # print()\n",
        "\n",
        "        cur_counter += 1\n",
        "        state = state_1\n",
        "\n",
        "def main(mode):\n",
        "    cuda_is_available = torch.cuda.is_available()\n",
        "\n",
        "    if mode == 'test':\n",
        "\n",
        "        model = torch.load(\n",
        "            'pretrained-model/current_model_500000.pth',\n",
        "            map_location='cpu' if not cuda_is_available else None\n",
        "        ).eval()\n",
        "\n",
        "        print(\"loaded\")\n",
        "\n",
        "        if cuda_is_available:\n",
        "            model = model.cuda()\n",
        "\n",
        "        test(model)\n",
        "\n",
        "    elif mode == 'train':\n",
        "        if not os.path.exists('pretrained-model/'):\n",
        "            os.mkdir('pretrained-model/')\n",
        "\n",
        "        model = NeuralNetwork()\n",
        "\n",
        "        if cuda_is_available:\n",
        "            model = model.cuda()\n",
        "\n",
        "        model.apply(init_weights)\n",
        "        start = time.time()\n",
        "\n",
        "        vals = train(model, start)\n",
        "        with open('q_vals.csv', 'w', newline='') as myfile:\n",
        "          wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "          wr.writerow(vals)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main('train')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-67e0f04ea9f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    }
  ]
}